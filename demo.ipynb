{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transition_rates_and_R(config,c):\n",
    "    L = config.shape[0]\n",
    "    transition_rates = (config*(1-c) + (1-config)*c) * ((np.roll(config, 1) + np.roll(config, -1)))\n",
    "    R = np.sum(transition_rates)\n",
    "    return transition_rates, R\n",
    "\n",
    "\n",
    "\n",
    "def sample_FA_trajectory(T,L,c):\n",
    "    t = 0\n",
    "    log_likelihood = 0\n",
    "    configs = np.zeros((int(T*L*c*1.5), L))\n",
    "    times = np.zeros((configs.shape[0]))\n",
    "\n",
    "    i = 0\n",
    "    config = np.random.choice([0,1], L, p= [1-c,c])\n",
    "    configs[i] = config\n",
    "\n",
    "    transition_rates, R = transition_rates_and_R(config,c)\n",
    "\n",
    "    dt = np.random.exponential(scale = 1/R, size = 1)[0]\n",
    "\n",
    "    while t + dt < T:\n",
    "\n",
    "        times[i] = dt\n",
    "        flip_id = np.random.choice(L, 1, p = transition_rates/R)[0]\n",
    "        log_likelihood += np.log(transition_rates[flip_id]) - times[i]*R\n",
    "\n",
    "        t += dt\n",
    "        i+=1\n",
    "\n",
    "        config = config.copy()\n",
    "        config[flip_id] = 1 - config[flip_id]\n",
    "        configs[i] = config\n",
    "        transition_rates, R = transition_rates_and_R(config,c)\n",
    "        dt = np.random.exponential(scale = 1/R, size = 1)[0]\n",
    "\n",
    "    times[i] = T-t\n",
    "    log_likelihood -= R*times[i]\n",
    "\n",
    "    return configs[:i+1],times[:i+1], log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, seq_length, embedding_dim, num_heads, num_layers, dim_feedforward):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "\n",
    "        self.seq_length = seq_length\n",
    "        self.spin_emb = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        self.pos_emb = torch.nn.Embedding(seq_length, embedding_dim)\n",
    "\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(embedding_dim, num_heads, dim_feedforward, dropout=0, batch_first = True)\n",
    "        self.transformer = torch.nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        model = []\n",
    "\n",
    "        model += [torch.nn.Linear(embedding_dim, 1)]\n",
    "        self.decoder = torch.nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        spin_emb = self.spin_emb(x)\n",
    "        b,t,k = spin_emb.size()\n",
    "        positions = torch.arange(self.seq_length, device=device)\n",
    "        pos_emb = self.pos_emb(positions)[None, :,:].expand(b,t,k)\n",
    "\n",
    "        input = spin_emb + pos_emb\n",
    "\n",
    "        output = self.transformer(input)\n",
    "\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class DynamicsLearner(torch.nn.Module):\n",
    "    def __init__(self,configs,times, exact, T, input_dim, embedding_dim, num_heads, num_layers, dim_feedforward):\n",
    "        super(DynamicsLearner, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "\n",
    "\n",
    "        self.L = configs[0].shape[0]\n",
    "\n",
    "        self.transformer_logrates = TransformerModel(input_dim, self.L, embedding_dim, num_heads, num_layers, dim_feedforward)\n",
    "        self.transformer_logrates.to(dtype).to(device)\n",
    "\n",
    "        self.times = torch.from_numpy(times).to(dtype)\n",
    "        self.configs = torch.from_numpy(configs).to(torch.int64)\n",
    "        self.exact = exact\n",
    "        self.T = T\n",
    "\n",
    "    def log_transition_rates_and_R_batched(self, configs):\n",
    "        configs = configs.to(device)\n",
    "        log_rates = self.transformer_logrates(configs)[...,0]\n",
    "        R = torch.sum(torch.exp(log_rates), dim =1)\n",
    "        return log_rates, R\n",
    "\n",
    "\n",
    "\n",
    "    def log_likelihood_trajectory_batched(self, start, end, calc_last = False):\n",
    "        log_transition_rates, R = self.log_transition_rates_and_R_batched(self.configs[start:end])\n",
    "        if not calc_last:\n",
    "            ids_flipped = torch.where(self.configs[start:end] - self.configs[start+1:end + 1])\n",
    "            log_likelihood = log_transition_rates[ids_flipped].sum() - (self.times[start:end].to(device)*R).sum()\n",
    "        else:\n",
    "            ids_flipped = torch.where(self.configs[start:end-1] - self.configs[start+1:end])\n",
    "            log_likelihood = log_transition_rates[:-1][ids_flipped].sum() - (self.times[start:end-1].to(device)*R[:-1]).sum()\n",
    "            log_likelihood -= R[-1]*self.times[-1].to(device)\n",
    "        return log_likelihood\n",
    "\n",
    "\n",
    "\n",
    "    def train_batched(self, n_iter, lr, batch_size,update_batch, batch_per_update, grad_clip):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr)\n",
    "\n",
    "        losses = np.zeros(n_iter)\n",
    "        steps = self.times.shape[0] // batch_size + 1  if batch_size < self.times.shape[0] else 1\n",
    "\n",
    "        for i in range(n_iter):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            running_loss = 0\n",
    "\n",
    "            for j in tqdm(range(steps)):\n",
    "                if j < steps - 1:\n",
    "                    loss = -1* (self.log_likelihood_trajectory_batched(j*batch_size, (j+1)*batch_size))\n",
    "                else:\n",
    "                    loss = -1 *(self.log_likelihood_trajectory_batched(j*batch_size, self.times.shape[0], calc_last = True))\n",
    "                loss.backward()\n",
    "                if update_batch and j % batch_per_update == 0:\n",
    "                    if grad_clip != 0:\n",
    "                        torch.nn.utils.clip_grad_norm_(self.parameters(), grad_clip)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "                running_loss += loss.detach()\n",
    "\n",
    "            if not update_batch:\n",
    "                if grad_clip != 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.parameters(), grad_clip)\n",
    "                optimizer.step()\n",
    "\n",
    "            tot_loss = running_loss.cpu().numpy()\n",
    "\n",
    "            losses[i] = tot_loss\n",
    "\n",
    "            print(\"Step: \"+ str(i+1)+\"\\t Exact: \" + str(self.exact/self.T) + \"\\t\"+\"Transformer: \" + str(-1*tot_loss/self.T))\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\t Exact: -4.064679727402805\tTransformer: -5.81061953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2\t Exact: -4.064679727402805\tTransformer: -4.61864921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3\t Exact: -4.064679727402805\tTransformer: -4.152382421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:04<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4\t Exact: -4.064679727402805\tTransformer: -4.115306640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5\t Exact: -4.064679727402805\tTransformer: -4.093308203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:04<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\t Exact: -4.064679727402805\tTransformer: -4.08111953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:04<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2\t Exact: -4.064679727402805\tTransformer: -4.076498046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:04<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3\t Exact: -4.064679727402805\tTransformer: -4.073109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:05<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4\t Exact: -4.064679727402805\tTransformer: -4.071220703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:04<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5\t Exact: -4.064679727402805\tTransformer: -4.07003203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jl/b1835h_x6252_qtjwmwpxb2w0000gn/T/ipykernel_79395/3358659408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mlosses_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdynamics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "T = 1e4\n",
    "L = 10\n",
    "c = 0.3\n",
    "\n",
    "configs,times, exact = sample_FA_trajectory(T, L, c)\n",
    "\n",
    "input_dim =2\n",
    "embedding_dim = 64\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "dim_feedforward = int(4*embedding_dim)\n",
    "\n",
    "dynamics = DynamicsLearner(configs,times, exact, T, input_dim, embedding_dim, num_heads, num_layers, dim_feedforward)\n",
    "\n",
    "\n",
    "num_iter = 5\n",
    "lr = 1e-3\n",
    "batch_size = int(1e3)\n",
    "update_batch = True\n",
    "batch_per_update = 1\n",
    "grad_clip = 100\n",
    "losses_batched = dynamics.train_batched(num_iter,lr , batch_size,update_batch, batch_per_update, grad_clip)\n",
    "\n",
    "num_iter = 5\n",
    "lr = 1e-4\n",
    "losses_full = dynamics.train_batched(num_iter,lr , batch_size,False, 0, grad_clip)\n",
    "\n",
    "losses = np.concatenate((losses_batched, losses_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(exact/T*np.ones_like(losses), ls = \"--\", color = \"k\")\n",
    "plt.plot(-1*losses/T)\n",
    "plt.xlabel(\"#epochs\")\n",
    "plt.ylabel(r\"$U_\\omega^\\theta/T$\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57d879c1bab31ddce3f98747a90aac1ecdf0d747d4f9b6f921c92f41b19b21c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('pytorch_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
